{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on Distributed Dask with SageMaker and Fargate\n",
    "\n",
    "This notebook will demonstrate how to perform Machine Learning on Distributed Dask using SageMaker and Fargate.  We will demo how to connect to distributed dask fargate cluster, scale out dask worker nodes, perform EDA work on public newyork cab trip data sets. Then, we demonstrate how you can run regression algorithms and hyperparameters optimization on distributed dask cluster. Next, we will demonstrate how you can monitor the operational metrics of Dask Cluster that will be fronted by Network Load Balancer for accessing the Dask Cluster Status UI from internet. Finally, we will close with how to build your own python script container and run against the dask fargate cluster.  This notebook was inspired by customer use case where they were running dask on local computer for building regression models.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge scikit-learn==0.23 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y dask=2.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge s3fs=0.3.0 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge matplotlib=3.3.1 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge dask-ml=1.6.0 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Dask Fargate Cluster.  You need to provision this cluster following the instructions from here https://github.com/rvvittal/aws-dask-sm-fargate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rvvittal/opt/anaconda3/lib/python3.7/site-packages/distributed/client.py:1137: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+---------------+---------------+---------------+\n",
      "| Package | client        | scheduler     | workers       |\n",
      "+---------+---------------+---------------+---------------+\n",
      "| blosc   | None          | 1.7.0         | 1.7.0         |\n",
      "| python  | 3.7.6.final.0 | 3.7.7.final.0 | 3.7.7.final.0 |\n",
      "+---------+---------------+---------------+---------------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client('localhost:8786')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale out the number of dask workers as needed for your data science work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws ecs update-service --service Dask-Workers --desired-count 20 --cluster Fargate-Dask-Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart the client after scale out operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dask dataframe with the trip data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Introduction to Dask DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import dask.dataframe as dd\n",
    "import boto3\n",
    "import dask.distributed\n",
    "#df = dd.read_csv('s3://octank-claims-web/public-data/yellow_tripdata_2018-01.csv', storage_options={'anon': False})\n",
    "# df = dd.read_csv('s3://nyc-tlc/trip data/green_tripdata_2018-02.csv', storage_options={'anon': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(\n",
    "    's3://nyc-tlc/trip data/green_tripdata_2018-02.csv', storage_options={'anon': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:39:38</td>\n",
       "      <td>2018-02-01 00:39:41</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:58:28</td>\n",
       "      <td>2018-02-01 01:05:35</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:56:05</td>\n",
       "      <td>2018-02-01 01:18:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>9.60</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:12:40</td>\n",
       "      <td>2018-02-01 00:15:50</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:45:18</td>\n",
       "      <td>2018-02-01 00:51:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1.87</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2018-02-01 00:39:38   2018-02-01 00:39:41                  N   \n",
       "1         2  2018-02-01 00:58:28   2018-02-01 01:05:35                  N   \n",
       "2         2  2018-02-01 00:56:05   2018-02-01 01:18:54                  N   \n",
       "3         2  2018-02-01 00:12:40   2018-02-01 00:15:50                  N   \n",
       "4         2  2018-02-01 00:45:18   2018-02-01 00:51:56                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           5            97            65                1           0.00   \n",
       "1           1           256            80                5           1.60   \n",
       "2           1            25            95                1           9.60   \n",
       "3           1            61            61                1           0.73   \n",
       "4           1            65            17                2           1.87   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         20.0    0.0      0.0        3.00           0.0        NaN   \n",
       "1          7.5    0.5      0.5        0.88           0.0        NaN   \n",
       "2         28.5    0.5      0.5        5.96           0.0        NaN   \n",
       "3          4.5    0.5      0.5        0.00           0.0        NaN   \n",
       "4          8.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \n",
       "0                    0.0         23.00             1          2  \n",
       "1                    0.3          9.68             1          1  \n",
       "2                    0.3         35.76             1          1  \n",
       "3                    0.3          5.80             2          1  \n",
       "4                    0.3          9.30             2          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and count number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist multiple Dask collections into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
      "0         2  2018-02-01 00:39:38   2018-02-01 00:39:41                  N   \n",
      "1         2  2018-02-01 00:58:28   2018-02-01 01:05:35                  N   \n",
      "2         2  2018-02-01 00:56:05   2018-02-01 01:18:54                  N   \n",
      "3         2  2018-02-01 00:12:40   2018-02-01 00:15:50                  N   \n",
      "4         2  2018-02-01 00:45:18   2018-02-01 00:51:56                  N   \n",
      "\n",
      "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
      "0           5            97            65                1           0.00   \n",
      "1           1           256            80                5           1.60   \n",
      "2           1            25            95                1           9.60   \n",
      "3           1            61            61                1           0.73   \n",
      "4           1            65            17                2           1.87   \n",
      "\n",
      "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
      "0         20.0    0.0      0.0        3.00           0.0        NaN   \n",
      "1          7.5    0.5      0.5        0.88           0.0        NaN   \n",
      "2         28.5    0.5      0.5        5.96           0.0        NaN   \n",
      "3          4.5    0.5      0.5        0.00           0.0        NaN   \n",
      "4          8.0    0.5      0.5        0.00           0.0        NaN   \n",
      "\n",
      "   improvement_surcharge  total_amount  payment_type  trip_type  \n",
      "0                    0.0         23.00             1          2  \n",
      "1                    0.3          9.68             1          1  \n",
      "2                    0.3         35.76             1          1  \n",
      "3                    0.3          5.80             2          1  \n",
      "4                    0.3          9.30             2          1  \n"
     ]
    }
   ],
   "source": [
    "df_persisted = client.persist(df)\n",
    "print(df_persisted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the mean trip distance grouped by the number of passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_count\n",
      "0    2.248809\n",
      "1    2.719773\n",
      "2    2.800221\n",
      "3    2.763138\n",
      "4    2.660013\n",
      "5    2.740212\n",
      "6    2.653089\n",
      "7    1.260000\n",
      "8    1.013571\n",
      "9    0.132500\n",
      "Name: trip_distance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped_df = df.groupby(df_persisted.passenger_count).trip_distance.mean().compute()\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Max trip distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.47\n"
     ]
    }
   ],
   "source": [
    "max_trip_dist = df_persisted.trip_distance.max().compute()\n",
    "print(max_trip_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the total trip distance and count for each vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72.1 ms, sys: 36.4 ms, total: 108 ms\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>Trip Count</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>131590</td>\n",
       "      <td>339995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>638350</td>\n",
       "      <td>1758388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID  Trip Count  trip_distance\n",
       "0         1      131590         339995\n",
       "1         2      638350        1758388"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.groupby('VendorID').agg({'passenger_count':'count', 'trip_distance': 'sum'}).astype(int).reset_index()\\\n",
    ".rename(columns={'passenger_count':'Trip Count'}).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Missing Values for Each Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                      0\n",
       "lpep_pickup_datetime          0\n",
       "lpep_dropoff_datetime         0\n",
       "store_and_fwd_flag            0\n",
       "RatecodeID                    0\n",
       "PULocationID                  0\n",
       "DOLocationID                  0\n",
       "passenger_count               0\n",
       "trip_distance                 0\n",
       "fare_amount                   0\n",
       "extra                         0\n",
       "mta_tax                       0\n",
       "tip_amount                    0\n",
       "tolls_amount                  0\n",
       "ehail_fee                769940\n",
       "improvement_surcharge         0\n",
       "total_amount                  0\n",
       "payment_type                  0\n",
       "trip_type                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Visual EDA  \n",
    "- ref https://medium.com/datadriveninvestor/analyzing-big-data-with-dask-a05a8798da8c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Selecting top 10 rides based on fare amount\n",
    "most_paid_rides_dask = df[['PULocationID', 'fare_amount']].nlargest(10, \"fare_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualizing most paid rides through Barplot\n",
    "import matplotlib.pyplot as plt\n",
    "most_paid_rides_dask.set_index('PULocationID',sorted=True).compute().plot(kind='barh',stacked=False, figsize=[10,8], legend=True)\n",
    "#######\n",
    "plt.title('Most Paid Rides')\n",
    "plt.xlabel('Fare Amount')\n",
    "plt.ylabel('PU LocationID')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualizing trip distance through Barplot\n",
    "import matplotlib.pyplot as plt\n",
    "most_paid_rides_dask2 = df[['trip_distance', 'fare_amount']].nlargest(10, \"trip_distance\")\n",
    "most_paid_rides_dask2.set_index('trip_distance',sorted=True).compute().plot(kind='bar', colormap='PiYG', stacked=False, figsize=[10,8], legend=True)\n",
    "#######\n",
    "plt.title('Fares by Distance')\n",
    "plt.xlabel('Trip Distance')\n",
    "plt.ylabel('Fare Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Regression modeling with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = dd.read_csv(\n",
    "    's3://nyc-tlc/trip data/green_tripdata_2018-02.csv', storage_options={'anon': True},\n",
    "    parse_dates=['lpep_pickup_datetime', 'lpep_dropoff_datetime'],\n",
    ").sample(frac=0.1, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl['trip_duration'] = dfl['lpep_dropoff_datetime'] - dfl['lpep_pickup_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dfl['trip_duration'] = dfl['trip_duration']/np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl['trip_duration'] = dfl['trip_duration'] * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=2\n",
       "    float64\n",
       "        ...\n",
       "        ...\n",
       "Name: trip_duration, dtype: float64\n",
       "Dask Name: getitem, 26 tasks"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl['trip_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601557</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-22 21:11:19</td>\n",
       "      <td>2018-02-22 21:24:43</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>3.05</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205086</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-08 11:40:40</td>\n",
       "      <td>2018-02-08 11:49:41</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450895</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-17 00:49:33</td>\n",
       "      <td>2018-02-17 00:54:43</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1.14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333002</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-12 21:26:55</td>\n",
       "      <td>2018-02-12 21:32:16</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264125</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-10 10:32:11</td>\n",
       "      <td>2018-02-10 10:35:34</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VendorID lpep_pickup_datetime lpep_dropoff_datetime  \\\n",
       "601557         2  2018-02-22 21:11:19   2018-02-22 21:24:43   \n",
       "205086         2  2018-02-08 11:40:40   2018-02-08 11:49:41   \n",
       "450895         2  2018-02-17 00:49:33   2018-02-17 00:54:43   \n",
       "333002         2  2018-02-12 21:26:55   2018-02-12 21:32:16   \n",
       "264125         2  2018-02-10 10:32:11   2018-02-10 10:35:34   \n",
       "\n",
       "       store_and_fwd_flag  RatecodeID  PULocationID  DOLocationID  \\\n",
       "601557                  N           1            97            79   \n",
       "205086                  N           1            69           116   \n",
       "450895                  N           1            80           112   \n",
       "333002                  N           1           149           178   \n",
       "264125                  N           1            75            75   \n",
       "\n",
       "        passenger_count  trip_distance  fare_amount  extra  mta_tax  \\\n",
       "601557                2           3.05         12.0    0.5      0.5   \n",
       "205086                5           1.02          7.5    0.0      0.5   \n",
       "450895                1           1.14          6.0    0.5      0.5   \n",
       "333002                1           1.07          6.0    0.5      0.5   \n",
       "264125                1           0.52          4.5    0.0      0.5   \n",
       "\n",
       "        tip_amount  tolls_amount  ehail_fee  improvement_surcharge  \\\n",
       "601557        2.66           0.0        NaN                    0.3   \n",
       "205086        0.00           0.0        NaN                    0.3   \n",
       "450895        1.46           0.0        NaN                    0.3   \n",
       "333002        0.00           0.0        NaN                    0.3   \n",
       "264125        0.00           0.0        NaN                    0.3   \n",
       "\n",
       "        total_amount  payment_type  trip_type  trip_duration  \n",
       "601557         15.96             1          1       0.223333  \n",
       "205086          8.30             1          1       0.150278  \n",
       "450895          8.76             1          1       0.086111  \n",
       "333002          7.30             1          1       0.089167  \n",
       "264125          5.30             2          1       0.056389  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = dfl.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = dd.get_dummies(dfl.categorize()).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>...</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>store_and_fwd_flag_N</th>\n",
       "      <th>store_and_fwd_flag_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601557</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-22 21:11:19</td>\n",
       "      <td>2018-02-22 21:24:43</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>3.05</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205086</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-08 11:40:40</td>\n",
       "      <td>2018-02-08 11:49:41</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450895</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-17 00:49:33</td>\n",
       "      <td>2018-02-17 00:54:43</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1.14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333002</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-12 21:26:55</td>\n",
       "      <td>2018-02-12 21:32:16</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264125</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-10 10:32:11</td>\n",
       "      <td>2018-02-10 10:35:34</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VendorID lpep_pickup_datetime lpep_dropoff_datetime  RatecodeID  \\\n",
       "601557         2  2018-02-22 21:11:19   2018-02-22 21:24:43           1   \n",
       "205086         2  2018-02-08 11:40:40   2018-02-08 11:49:41           1   \n",
       "450895         2  2018-02-17 00:49:33   2018-02-17 00:54:43           1   \n",
       "333002         2  2018-02-12 21:26:55   2018-02-12 21:32:16           1   \n",
       "264125         2  2018-02-10 10:32:11   2018-02-10 10:35:34           1   \n",
       "\n",
       "        PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "601557            97            79                2           3.05   \n",
       "205086            69           116                5           1.02   \n",
       "450895            80           112                1           1.14   \n",
       "333002           149           178                1           1.07   \n",
       "264125            75            75                1           0.52   \n",
       "\n",
       "        fare_amount  extra  ...  tip_amount  tolls_amount  ehail_fee  \\\n",
       "601557         12.0    0.5  ...        2.66           0.0        0.0   \n",
       "205086          7.5    0.0  ...        0.00           0.0        0.0   \n",
       "450895          6.0    0.5  ...        1.46           0.0        0.0   \n",
       "333002          6.0    0.5  ...        0.00           0.0        0.0   \n",
       "264125          4.5    0.0  ...        0.00           0.0        0.0   \n",
       "\n",
       "        improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "601557                    0.3         15.96             1          1   \n",
       "205086                    0.3          8.30             1          1   \n",
       "450895                    0.3          8.76             1          1   \n",
       "333002                    0.3          7.30             1          1   \n",
       "264125                    0.3          5.30             2          1   \n",
       "\n",
       "        trip_duration  store_and_fwd_flag_N  store_and_fwd_flag_Y  \n",
       "601557       0.223333                     1                     0  \n",
       "205086       0.150278                     1                     0  \n",
       "450895       0.086111                     1                     0  \n",
       "333002       0.089167                     1                     0  \n",
       "264125       0.056389                     1                     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfl[['VendorID','RatecodeID','PULocationID','DOLocationID','passenger_count','trip_distance','fare_amount','total_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfl['trip_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69294, 7700, 69294, 7700)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = X_train.values\n",
    "training_y = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_x = X_test.values\n",
    "testing_y = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(preds, actuals):\n",
    "    error = mean_squared_error(actuals, preds)\n",
    "    rmse = np.sqrt(error)\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.linear_model import LinearRegression\n",
    "lr = LinearRegression(random_state=1, n_jobs=-1, fit_intercept=True)\n",
    "lr.fit(training_x,training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    lr = LinearRegression(random_state=1, fit_intercept=False)\n",
    "    lr.fit(training_x,training_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Dask distributed machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 160.00 MB </td> <td> 8.00 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (200000, 100) </td> <td> (10000, 100) </td></tr>\n",
       "    <tr><th> Count </th><td> 20 Tasks </td><td> 20 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"25\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"25\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"30\" x2=\"25\" y2=\"30\" />\n",
       "  <line x1=\"0\" y1=\"36\" x2=\"25\" y2=\"36\" />\n",
       "  <line x1=\"0\" y1=\"42\" x2=\"25\" y2=\"42\" />\n",
       "  <line x1=\"0\" y1=\"48\" x2=\"25\" y2=\"48\" />\n",
       "  <line x1=\"0\" y1=\"54\" x2=\"25\" y2=\"54\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"25\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"66\" x2=\"25\" y2=\"66\" />\n",
       "  <line x1=\"0\" y1=\"72\" x2=\"25\" y2=\"72\" />\n",
       "  <line x1=\"0\" y1=\"78\" x2=\"25\" y2=\"78\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"25\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"90\" x2=\"25\" y2=\"90\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"25\" y2=\"96\" />\n",
       "  <line x1=\"0\" y1=\"102\" x2=\"25\" y2=\"102\" />\n",
       "  <line x1=\"0\" y1=\"108\" x2=\"25\" y2=\"108\" />\n",
       "  <line x1=\"0\" y1=\"114\" x2=\"25\" y2=\"114\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 25.412617,0.000000 25.412617,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >100</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">200000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<normal, shape=(200000, 100), dtype=float64, chunksize=(10000, 100), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_glm.datasets import make_regression\n",
    "X, y = make_regression(n_samples=200000, n_features=100, n_informative=5, chunksize=10000)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "X, y = dask.persist(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_glm.algorithms\n",
    "\n",
    "b = dask_glm.algorithms.admm(X, y, max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dask_glm.algorithms.proximal_grad(X, y, max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_glm.families\n",
    "import dask_glm.regularizers\n",
    "\n",
    "family = dask_glm.families.Poisson()\n",
    "regularizer = dask_glm.regularizers.ElasticNet()\n",
    "\n",
    "b = dask_glm.algorithms.proximal_grad(\n",
    "    X, y,\n",
    "    max_iter=5,\n",
    "    family=family,\n",
    "    regularizer=regularizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Dask distributed machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn uses joblib for single-machine parallelism. This lets you train most estimators (anything that accepts an n_jobs parameter) using all the cores of your laptop or workstation.Alternatively, Scikit-Learn can use Dask for parallelism. This lets you train those estimators using all the cores of your cluster without significantly changing your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06377997,  0.67640868,  1.06935647, -0.21758002,  0.46021477,\n",
       "        -0.39916689, -0.07918751,  1.20938491, -0.78531472, -0.17218611,\n",
       "        -1.08535744, -0.99311895,  0.30693511,  0.06405769, -1.0542328 ,\n",
       "        -0.52749607, -0.0741832 , -0.35562842,  1.05721416, -0.90259159],\n",
       "       [ 0.0708476 , -1.69528125,  2.44944917, -0.5304942 , -0.93296221,\n",
       "         2.86520354,  2.43572851, -1.61850016,  1.30071691,  0.34840246,\n",
       "         0.54493439,  0.22532411,  0.60556322, -0.19210097, -0.06802699,\n",
       "         0.9716812 , -1.79204799,  0.01708348, -0.37566904, -0.62323644],\n",
       "       [ 0.94028404, -0.49214582,  0.67795602, -0.22775445,  1.40175261,\n",
       "         1.23165333, -0.77746425,  0.01561602,  1.33171299,  1.08477266,\n",
       "        -0.97805157, -0.05012039,  0.94838552, -0.17342825, -0.47767184,\n",
       "         0.76089649,  1.00115812, -0.06946407,  1.35904607, -1.18958963],\n",
       "       [-0.29951677,  0.75988955,  0.18280267, -1.55023271,  0.33821802,\n",
       "         0.36324148, -2.10052547, -0.4380675 , -0.16639343, -0.34083531,\n",
       "         0.42435643,  1.17872434,  2.8314804 ,  0.14241375, -0.20281911,\n",
       "         2.40571546,  0.31330473,  0.40435568, -0.28754632, -2.8478034 ],\n",
       "       [-2.63062675,  0.23103376,  0.04246253,  0.47885055,  1.54674163,\n",
       "         1.6379556 , -1.53207229, -0.73444479,  0.46585484,  0.4738362 ,\n",
       "         0.98981401, -1.06119392, -0.88887952,  1.23840892, -0.57282854,\n",
       "        -1.27533949,  1.0030065 , -0.47712843,  0.09853558,  0.52780407]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, random_state=0)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"shrinking\": [True, False]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
    "                           param_grid=param_grid,\n",
    "                           return_train_score=False,\n",
    "                           iid=True,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rvvittal/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=SVC(gamma='auto', probability=True, random_state=0),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid'],\n",
       "                         'shrinking': [True, False]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rvvittal/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_shrinking</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155570</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'rbf', 'shrinking': True}</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.190303</td>\n",
       "      <td>0.038406</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'rbf', 'shrinking': False}</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068233</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'poly', 'shrinking': True}</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085549</td>\n",
       "      <td>0.009503</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'poly', 'shrinking': Fa...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172430</td>\n",
       "      <td>0.015639</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'kernel': 'sigmoid', 'shrinking':...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.155570      0.011876         0.013422        0.001323   0.001   \n",
       "1       0.190303      0.038406         0.010841        0.000753   0.001   \n",
       "2       0.068233      0.007792         0.008976        0.002419   0.001   \n",
       "3       0.085549      0.009503         0.006081        0.000797   0.001   \n",
       "4       0.172430      0.015639         0.013679        0.001162   0.001   \n",
       "\n",
       "  param_kernel param_shrinking  \\\n",
       "0          rbf            True   \n",
       "1          rbf           False   \n",
       "2         poly            True   \n",
       "3         poly           False   \n",
       "4      sigmoid            True   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0   {'C': 0.001, 'kernel': 'rbf', 'shrinking': True}           0.502994   \n",
       "1  {'C': 0.001, 'kernel': 'rbf', 'shrinking': False}           0.502994   \n",
       "2  {'C': 0.001, 'kernel': 'poly', 'shrinking': True}           0.502994   \n",
       "3  {'C': 0.001, 'kernel': 'poly', 'shrinking': Fa...           0.502994   \n",
       "4  {'C': 0.001, 'kernel': 'sigmoid', 'shrinking':...           0.502994   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.501502           0.501502            0.502        0.000704   \n",
       "1           0.501502           0.501502            0.502        0.000704   \n",
       "2           0.501502           0.501502            0.502        0.000704   \n",
       "3           0.501502           0.501502            0.502        0.000704   \n",
       "4           0.501502           0.501502            0.502        0.000704   \n",
       "\n",
       "   rank_test_score  \n",
       "0               41  \n",
       "1               41  \n",
       "2               41  \n",
       "3               41  \n",
       "4               41  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your python script container for your machine learning work.  \n",
    "### Make sure to follow the steps in github repo for building/deploying this container before running this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 716664005094.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -e s3url='s3://nyc-tlc/trip data/green_tripdata_2018-02.csv' -e schurl='tcp://Dask-Scheduler.local-dask:8786' 716664005094.dkr.ecr.us-west-2.amazonaws.com/daskclientapp:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale in the Fargate cluster worker nodes after all work is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge awscli -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!aws ecs update-service --service Dask-Workers --desired-count 1 --cluster Fargate-Dask-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
